run_name: aigcode-7B-sft
seed: 3477
dry_run: false
gpu_type: ascend

# wandb:
#  entity: aigcode
#  name: ${run_name}
#  project: aigcode_sft_7B
#  group: aigcode-7B-sft_v1.0

model:
  d_model: 4096
  n_heads: 32
  n_layers: 22
  mlp_ratio: 4
  weight_tying: false
  alibi: false
  rope: true
  rope_base: 30000
  flash_attention: false  # not available on AMD
  attention_dropout: 0.0
  attention_layer_norm: false
  multi_query_attention: false
  include_bias: false
  block_type: sequential
  layer_norm_type: default
  layer_norm_with_affine: false
  bias_for_layer_norm: false
  attention_layer_norm_with_affine: false
  activation_type: swiglu
  residual_dropout: 0.0
  embedding_dropout: 0.0
  max_sequence_length: 4096
  vocab_size: 64000
  embedding_size: 65280
  eos_token_id: 2
  pad_token_id: 0
  init_device: meta
  init_std: 0.01
  gate_softmax_temperature: 8.0
  intermediate_size: 16384

  use_xmoe: true
  use_ple: false
  ple_layer_num: 0
  ple_layernorm: false
  moe_freq: 2
  moe_topn_expert: 1
  moe_top1_expert: true
  gate_level: token
  exp_dim_ratio: 1
  moe_expert_count: 4
  moe_share_expert_count: 0
  moe_gate_loss_weight: 0.
  moe_gate_loss_combine_method: average
  moe_gating_use_fp32: true
  moe_second_expert_policy: sampling
  moe_normalize_gate_prob_before_dropping: false
  moe_auxiliary_loss: false
  moe_gate_no_grad: false

distributed_strategy: fsdp
compile: null  # causes instability on AMD GPUs

optimizer:
  name: adamw
  learning_rate: 3.0e-5
  weight_decay: 0.1
  betas:
  - 0.9
  - 0.95
  metrics_log_interval: 10

scheduler:
  name: constant


tokenizer:
  identifier: tokenizers/neo_chat_tokenizer.json
  truncate_direction: right

save_folder: ${path.choose:${oc.env:SCRATCH_DIR,no_exist}/checkpoints,/results}/${oc.env:SLURM_JOB_ID,${run_name}}
save_overwrite: false
# Do not save sharded checkpoints for saving memory
save_interval: 1000000
save_num_checkpoints_to_keep: 0
# Unsharded checkpoints (for final storage)
save_interval_unsharded: 5000
save_num_unsharded_checkpoints_to_keep: -1

load_path: results/AIGCode-7B/step290000-unsharded
reset_trainer_state: true
reset_optimizer_state: true
# 15.7B tokens
max_duration: 3000
global_train_batch_size: 1280
device_train_microbatch_size: 2

precision: amp_bf16

activation_checkpointing: one_in_two


fsdp:
  wrapping_strategy: by_block
  sharding_strategy: HYBRID_SHARD 
  precision: mixed

max_grad_norm: 1.0
max_grad_norm_ratio: null
moe_params_isolation: false

speed_monitor:
  window_size: 20

eval_interval: 1000
eval_subset_num_batches: -1
device_eval_batch_size: ${device_train_microbatch_size}
evaluators:
  - label: m-a-p-small-ppl-validation
    data:
      num_workers: 0
      drop_last: true
      datasets:
        cc_en-validation:
          - /dataset/m-a-p/Matrix/npy/cc_en.0000.jsonl.npy
          - /dataset/m-a-p/Matrix/npy/cc_en.0001.jsonl.npy
          - /dataset/m-a-p/Matrix/npy/cc_en.0002.jsonl.npy
          - /dataset/m-a-p/Matrix/npy/cc_en.0003.jsonl.npy
          - /dataset/m-a-p/Matrix/npy/cc_en.0004.jsonl.npy
        cc_zh-validation:
          - /dataset/m-a-p/Matrix/npy/cc_zh.0000.jsonl.npy
          - /dataset/m-a-p/Matrix/npy/cc_zh.0001.jsonl.npy
        
  - label: v3-small-ppl-validation
    data:
      num_workers: 0
      drop_last: true
      datasets:
        v3-small-c4_en-validation:
          - /dataset/v3_small_gptneox20b/c4_en/part-0-00000.npy
        v3-small-dolma_books-validation:
          - /dataset/v3_small_gptneox20b/dolma_books/part-0-00000.npy
        v3-small-dolma_common-crawl-validation:
          - /dataset/v3_small_gptneox20b/dolma_common-crawl/part-0-00000.npy
        v3-small-dolma_pes2o-validation:
          - /dataset/v3_small_gptneox20b/dolma_pes2o/part-0-00000.npy
        v3-small-dolma_reddit-validation:
          - /dataset/v3_small_gptneox20b/dolma_reddit/part-0-00000.npy
        v3-small-dolma_stack-validation:
          - /dataset/v3_small_gptneox20b/dolma_stack/part-0-00000.npy
        v3-small-dolma_wiki-validation:
          - /dataset/v3_small_gptneox20b/dolma_wiki/part-0-00000.npy
        v3-small-ice-validation:
          - /dataset/v3_small_gptneox20b/ice/part-0-00000.npy
        v3-small-m2d2_s2orc-validation:
          - /dataset/v3_small_gptneox20b/m2d2_s2orc/part-0-00000.npy
        v3-small-pile-validation:
          - /dataset/v3_small_gptneox20b/pile/part-0-00000.npy
        v3-small-wikitext_103-validation:
          - /dataset/v3_small_gptneox20b/wikitext_103/part-0-00000.npy

  - label: v2-small-ppl-validation
    data:
      num_workers: 0
      drop_last: true
      datasets:
        v2-small-4chan-validation:
          - /dataset/v2_small_gptneox20b/4chan/val.npy
        v2-small-c4_100_domains-validation:
          - /dataset/v2_small_gptneox20b/c4_100_domains/val.npy
        v2-small-c4_en-validation:
          - /dataset/v2_small_gptneox20b/c4_en/val.npy
        v2-small-gab-validation:
          - /dataset/v2_small_gptneox20b/gab/val.npy
        v2-small-ice-validation:
          - /dataset/v2_small_gptneox20b/ice/val.npy
        v2-small-m2d2_s2orc-validation:
          - /dataset/v2_small_gptneox20b/m2d2_s2orc/val.npy
        v2-small-m2d2_wiki-validation:
          - /dataset/v2_small_gptneox20b/m2d2_wiki/val.npy
        v2-small-manosphere-validation:
          - /dataset/v2_small_gptneox20b/manosphere/val.npy
        v2-small-mc4_en-validation:
          - /dataset/v2_small_gptneox20b/mc4_en/val.npy
        v2-small-pile-validation:
          - /dataset/v2_small_gptneox20b/pile/val.npy
        v2-small-ptb-validation:
          - /dataset/v2_small_gptneox20b/ptb/val.npy
        v2-small-twitterAEE-validation:
          - /dataset/v2_small_gptneox20b/twitterAEE/val.npy
        v2-small-wikitext_103-validation:
          - /dataset/v2_small_gptneox20b/wikitext_103/val.npy

data:
  pad_direction: right
  num_workers: 8
  drop_last: true
  pin_memory: true
  prefetch_factor: 16
  persistent_workers: true
  timeout: 0
  memmap_dtype: uint16
  data_dir_prefix: "/dataset/pretrain/npy"
  data_dir:
    - sft: 1.0